{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug SqueezeNet v1.1 OpenCL implement with PyOpenCL and PyTorch\n",
    "Partial code are copied heavily from https://github.com/pytorch/vision/blob/master/torchvision/models/squeezenet.py  \n",
    "SqueezeNet Paper:https://arxiv.org/abs/1602.07360  \n",
    "SqueezeNet 1.1 model from https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1   \n",
    "SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters than SqueezeNet 1.0, without sacrificing accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some set up\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "import math\n",
    "import time\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test top-1 accuracy on pytorch pre-trained SqueezeNet v1.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build fire unit and SqueezeNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# squeeze_planes(1x1 conv) - (expand1x1_planes + expand3x3_planes)\n",
    "class Fire(nn.Module):\n",
    "    \n",
    "    def __init__(self, inplanes, squeeze_planes,\n",
    "                 expand1x1_planes, expand3x3_planes):\n",
    "        super(Fire, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
    "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
    "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
    "                                   kernel_size=1)\n",
    "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
    "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
    "                                   kernel_size=3, padding=1)\n",
    "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.squeeze_activation(self.squeeze(x))\n",
    "        return torch.cat([\n",
    "            self.expand1x1_activation(self.expand1x1(x)),\n",
    "            self.expand3x3_activation(self.expand3x3(x))], 1)\n",
    "\n",
    "class SqueezeNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(SqueezeNet, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "            Fire(64, 16, 64, 64),\n",
    "            Fire(128, 16, 64, 64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "            Fire(128, 32, 128, 128),\n",
    "            Fire(256, 32, 128, 128),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "            Fire(256, 48, 192, 192),\n",
    "            Fire(384, 48, 192, 192),\n",
    "            Fire(384, 64, 256, 256),\n",
    "            Fire(512, 64, 256, 256),\n",
    "        )\n",
    "        # Final convolution is initialized differently form the rest\n",
    "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            final_conv,\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool2d(13, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x.view(x.size(0), self.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load validation image: ILSVRC2012 validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data loading code\n",
    "# batch_size 64 consumes about 3.3GB of gpu memory \n",
    "cudnn.benchmark = True\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [ 0.485, 0.456, 0.406 ],\n",
    "                         std = [ 0.229, 0.224, 0.225 ]),\n",
    "])\n",
    "\n",
    "val_batch_size = 10\n",
    "valdir = './imagenet/val/'\n",
    "val = datasets.ImageFolder(valdir, transform)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=val_batch_size,shuffle=False, pin_memory = True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate top-1 accuracy of the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SqueezeNet()\n",
    "model.load_state_dict(torch.load('squeezenet1_1.pth'))\n",
    "\n",
    "#model.cuda()# using gpu\n",
    "model.eval()# for dropout layer\n",
    "\n",
    "# correct = 0.0\n",
    "# total = 0.0\n",
    "# for i, (images, labels) in enumerate(val_loader):\n",
    "#     images = Variable(images)\n",
    "    \n",
    "#     # get output\n",
    "#     output = model(images)\n",
    "#     _, predicted = torch.max(output.data, 1)\n",
    "#     total += labels.size(0)\n",
    "#     correct += (predicted.cpu() == labels).sum()\n",
    "    \n",
    "# acc_val = 100.0 * correct / total\n",
    "# print(\"Top-1 accuracy on validation set: %.4f\" % acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test if the OpenCL implement is correct\n",
    "By comprare the result of OpenCL implement and PyTorch implement using a single image as input  \n",
    "error = ((OpenCL_implement_class_socores - PyTorch_implement_class_socores) ^ 2).sum(element_wise)  \n",
    "If the OpenCL implement is correct, error should be relativly small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the test image\n",
    "im_path = r'cat.jpg'\n",
    "im = Image.open(im_path)\n",
    "\n",
    "#visualize the image\n",
    "imshow(im)\n",
    "\n",
    "#preprocess of the imput image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [ 0.485, 0.456, 0.406 ],\n",
    "                         std = [ 0.229, 0.224, 0.225 ]),\n",
    "])\n",
    "im_input = transform(im)\n",
    "\n",
    "#add a new axis for pytorch\n",
    "im_input = im_input.numpy()\n",
    "im_input = im_input[np.newaxis,:]\n",
    "im_input = torch.from_numpy(im_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "im_input_torch = Variable(im_input)\n",
    "im_output_torch = model(im_input_torch)\n",
    "_, predicted = torch.max(im_output_torch.data, 1)\n",
    "print('the label index prediction of pytorch implement: %d' % predicted.numpy()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load OpenCL implement\n",
    "deviceinfo.py and partial pyopencl code are from Hands On OpenCL  \n",
    "https://handsonopencl.github.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step1: OpenCL preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OpenCL setup\n",
    "import pyopencl as cl\n",
    "import deviceinfo\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ask the user to select a platform/device on the CLI\n",
    "context = cl.create_some_context()\n",
    "\n",
    "# Print out device info\n",
    "deviceinfo.output_device_info(context.devices[0])\n",
    "\n",
    "# Create a command queue\n",
    "queue = cl.CommandQueue(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: import parameters from pytorch implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = model.state_dict() \n",
    "\n",
    "#remove # to see the params index\n",
    "for k,v in params.items():\n",
    "    #print parameter name\n",
    "    print(k,params[k].numpy().shape)\n",
    "\n",
    "conv1_weight = params['features.0.weight'].numpy().reshape(-1)\n",
    "conv1_bias = params['features.0.bias'].numpy()\n",
    "\n",
    "#fire - fire - maxpool block 1\n",
    "fire1_squeeze_weight = params['features.3.squeeze.weight'].numpy().reshape(-1)\n",
    "fire1_squeeze_bias = params['features.3.squeeze.bias'].numpy()\n",
    "\n",
    "fire1_expand1x1_weight = params['features.3.expand1x1.weight'].numpy().reshape(-1)\n",
    "fire1_expand1x1_bias = params['features.3.expand1x1.bias'].numpy()\n",
    "\n",
    "fire1_expand3x3_weight = params['features.3.expand3x3.weight'].numpy().reshape(-1)\n",
    "fire1_expand3x3_bias = params['features.3.expand3x3.bias'].numpy()\n",
    "\n",
    "fire2_squeeze_weight = params['features.4.squeeze.weight'].numpy().reshape(-1)\n",
    "fire2_squeeze_bias = params['features.4.squeeze.bias'].numpy()\n",
    "\n",
    "fire2_expand1x1_weight = params['features.4.expand1x1.weight'].numpy().reshape(-1)\n",
    "fire2_expand1x1_bias = params['features.4.expand1x1.bias'].numpy()\n",
    "\n",
    "fire2_expand3x3_weight = params['features.4.expand3x3.weight'].numpy().reshape(-1)\n",
    "fire2_expand3x3_bias = params['features.4.expand3x3.bias'].numpy()\n",
    "\n",
    "#fire - fire - maxpool block 2\n",
    "fire3_squeeze_weight = params['features.6.squeeze.weight'].numpy().reshape(-1)\n",
    "fire3_squeeze_bias = params['features.6.squeeze.bias'].numpy()\n",
    "\n",
    "fire3_expand1x1_weight = params['features.6.expand1x1.weight'].numpy().reshape(-1)\n",
    "fire3_expand1x1_bias = params['features.6.expand1x1.bias'].numpy()\n",
    "\n",
    "fire3_expand3x3_weight = params['features.6.expand3x3.weight'].numpy().reshape(-1)\n",
    "fire3_expand3x3_bias = params['features.6.expand3x3.bias'].numpy()\n",
    "\n",
    "fire4_squeeze_weight = params['features.7.squeeze.weight'].numpy().reshape(-1)\n",
    "fire4_squeeze_bias = params['features.7.squeeze.bias'].numpy()\n",
    "\n",
    "fire4_expand1x1_weight = params['features.7.expand1x1.weight'].numpy().reshape(-1)\n",
    "fire4_expand1x1_bias = params['features.7.expand1x1.bias'].numpy()\n",
    "\n",
    "fire4_expand3x3_weight = params['features.7.expand3x3.weight'].numpy().reshape(-1)\n",
    "fire4_expand3x3_bias = params['features.7.expand3x3.bias'].numpy()\n",
    "\n",
    "#fire - fire - fire - fire block 3\n",
    "fire5_squeeze_weight = params['features.9.squeeze.weight'].numpy().reshape(-1)\n",
    "fire5_squeeze_bias = params['features.9.squeeze.bias'].numpy()\n",
    "\n",
    "fire5_expand1x1_weight = params['features.9.expand1x1.weight'].numpy().reshape(-1)\n",
    "fire5_expand1x1_bias = params['features.9.expand1x1.bias'].numpy()\n",
    "\n",
    "fire5_expand3x3_weight = params['features.9.expand3x3.weight'].numpy().reshape(-1)\n",
    "fire5_expand3x3_bias = params['features.9.expand3x3.bias'].numpy()\n",
    "\n",
    "fire6_squeeze_weight = params['features.10.squeeze.weight'].numpy().reshape(-1)\n",
    "fire6_squeeze_bias = params['features.10.squeeze.bias'].numpy()\n",
    "\n",
    "fire6_expand1x1_weight = params['features.10.expand1x1.weight'].numpy().reshape(-1)\n",
    "fire6_expand1x1_bias = params['features.10.expand1x1.bias'].numpy()\n",
    "\n",
    "fire6_expand3x3_weight = params['features.10.expand3x3.weight'].numpy().reshape(-1)\n",
    "fire6_expand3x3_bias = params['features.10.expand3x3.bias'].numpy()\n",
    "\n",
    "fire7_squeeze_weight = params['features.11.squeeze.weight'].numpy().reshape(-1)\n",
    "fire7_squeeze_bias = params['features.11.squeeze.bias'].numpy()\n",
    "\n",
    "fire7_expand1x1_weight = params['features.11.expand1x1.weight'].numpy().reshape(-1)\n",
    "fire7_expand1x1_bias = params['features.11.expand1x1.bias'].numpy()\n",
    "\n",
    "fire7_expand3x3_weight = params['features.11.expand3x3.weight'].numpy().reshape(-1)\n",
    "fire7_expand3x3_bias = params['features.11.expand3x3.bias'].numpy()\n",
    "\n",
    "fire8_squeeze_weight = params['features.12.squeeze.weight'].numpy().reshape(-1)\n",
    "fire8_squeeze_bias = params['features.12.squeeze.bias'].numpy()\n",
    "\n",
    "fire8_expand1x1_weight = params['features.12.expand1x1.weight'].numpy().reshape(-1)\n",
    "fire8_expand1x1_bias = params['features.12.expand1x1.bias'].numpy()\n",
    "\n",
    "fire8_expand3x3_weight = params['features.12.expand3x3.weight'].numpy().reshape(-1)\n",
    "fire8_expand3x3_bias = params['features.12.expand3x3.bias'].numpy()\n",
    "\n",
    "classifier_conv_weight = params['classifier.1.weight'].numpy().reshape(-1)\n",
    "classifier_conv_bias = params['classifier.1.bias'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params['classifier.1.weight'][999][510][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat OpenCL memory object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_sample = im_input.numpy().reshape(-1)\n",
    "h_result_conv = np.empty(1 * 64 * 111 * 111).astype(np.float32)\n",
    "h_result_pool1 = np.empty(1 * 64 * 55 * 55).astype(np.float32)\n",
    "\n",
    "h_result_fire1_squeeze = np.empty(1 * 16 * 55 * 55).astype(np.float32)\n",
    "h_result_fire1_expand = np.empty(1 * 128 * 55 * 55).astype(np.float32)\n",
    "h_result_fire2_squeeze = np.empty(1 * 16 * 55 * 55).astype(np.float32)\n",
    "h_result_fire2_expand = np.empty(1 * 128 * 55 * 55).astype(np.float32)\n",
    "h_result_pool2 = np.empty(1 * 128 * 27 * 27).astype(np.float32)\n",
    "\n",
    "h_result_fire3_squeeze = np.empty(1 * 32 * 27 * 27).astype(np.float32)\n",
    "h_result_fire3_expand = np.empty(1 * 256 * 27 * 27).astype(np.float32)\n",
    "h_result_fire4_squeeze = np.empty(1 * 32 * 27 * 27).astype(np.float32)\n",
    "h_result_fire4_expand = np.empty(1 * 256 * 27 * 27).astype(np.float32)\n",
    "h_result_pool3 = np.empty(1 * 256 * 13 * 13).astype(np.float32)\n",
    "\n",
    "h_result_fire5_squeeze = np.empty(1 * 48 * 13 * 13).astype(np.float32)\n",
    "h_result_fire5_expand = np.empty(1 * 384 * 13 * 13).astype(np.float32)\n",
    "h_result_fire6_squeeze = np.empty(1 * 48 * 13 * 13).astype(np.float32)\n",
    "h_result_fire6_expand = np.empty(1 * 384 * 13 * 13).astype(np.float32)\n",
    "h_result_fire7_squeeze = np.empty(1 * 64 * 13 * 13).astype(np.float32)\n",
    "h_result_fire7_expand = np.empty(1 * 512 * 13 * 13).astype(np.float32)\n",
    "h_result_fire8_squeeze = np.empty(1 * 64 * 13 * 13).astype(np.float32)\n",
    "h_result_fire8_expand = np.empty(1 * 512 * 13 * 13).astype(np.float32)\n",
    "\n",
    "h_result_classifier_conv = np.empty(1 * 1000 * 13 * 13).astype(np.float32)\n",
    "h_result_classifier = np.empty(1 * 1000).astype(np.float32)\n",
    "\n",
    "# device input buffer\n",
    "d_sample = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_sample)\n",
    "\n",
    "# device conv1 buffers \n",
    "d_conv1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=conv1_weight)\n",
    "d_conv1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=conv1_bias)\n",
    "\n",
    "d_fire1_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_weight)\n",
    "d_fire1_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_squeeze_bias)\n",
    "d_fire1_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_weight)\n",
    "d_fire1_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand1x1_bias)\n",
    "d_fire1_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_weight)\n",
    "d_fire1_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire1_expand3x3_bias)\n",
    "\n",
    "d_fire2_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_weight)\n",
    "d_fire2_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_squeeze_bias)\n",
    "d_fire2_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_weight)\n",
    "d_fire2_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand1x1_bias)\n",
    "d_fire2_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_weight)\n",
    "d_fire2_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire2_expand3x3_bias)\n",
    "\n",
    "d_fire3_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_squeeze_weight)\n",
    "d_fire3_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_squeeze_bias)\n",
    "d_fire3_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand1x1_weight)\n",
    "d_fire3_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand1x1_bias)\n",
    "d_fire3_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand3x3_weight)\n",
    "d_fire3_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire3_expand3x3_bias)\n",
    "\n",
    "d_fire4_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_squeeze_weight)\n",
    "d_fire4_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_squeeze_bias)\n",
    "d_fire4_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand1x1_weight)\n",
    "d_fire4_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand1x1_bias)\n",
    "d_fire4_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand3x3_weight)\n",
    "d_fire4_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire4_expand3x3_bias)\n",
    "\n",
    "d_fire5_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_squeeze_weight)\n",
    "d_fire5_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_squeeze_bias)\n",
    "d_fire5_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand1x1_weight)\n",
    "d_fire5_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand1x1_bias)\n",
    "d_fire5_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand3x3_weight)\n",
    "d_fire5_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire5_expand3x3_bias)\n",
    "\n",
    "d_fire6_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_weight)\n",
    "d_fire6_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_squeeze_bias)\n",
    "d_fire6_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_weight)\n",
    "d_fire6_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand1x1_bias)\n",
    "d_fire6_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_weight)\n",
    "d_fire6_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire6_expand3x3_bias)\n",
    "\n",
    "d_fire7_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_weight)\n",
    "d_fire7_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_squeeze_bias)\n",
    "d_fire7_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_weight)\n",
    "d_fire7_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand1x1_bias)\n",
    "d_fire7_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_weight)\n",
    "d_fire7_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire7_expand3x3_bias)\n",
    "\n",
    "d_fire8_squeeze_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_weight)\n",
    "d_fire8_squeeze_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_squeeze_bias)\n",
    "d_fire8_expand1x1_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_weight)\n",
    "d_fire8_expand1x1_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand1x1_bias)\n",
    "d_fire8_expand3x3_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_weight)\n",
    "d_fire8_expand3x3_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=fire8_expand3x3_bias)\n",
    "\n",
    "d_classifier_conv_weight = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=classifier_conv_weight)\n",
    "d_classifier_conv_bias = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=classifier_conv_bias)\n",
    "\n",
    "d_result_conv = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_conv.nbytes)\n",
    "d_result_pool1 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool1.nbytes)\n",
    "\n",
    "d_result_fire1_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_squeeze.nbytes)\n",
    "d_result_fire1_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire1_expand.nbytes)\n",
    "d_result_fire2_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_squeeze.nbytes)\n",
    "d_result_fire2_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire2_expand.nbytes)\n",
    "d_result_pool2 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool2.nbytes)\n",
    "\n",
    "d_result_fire3_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire3_squeeze.nbytes)\n",
    "d_result_fire3_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire3_expand.nbytes)\n",
    "d_result_fire4_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire4_squeeze.nbytes)\n",
    "d_result_fire4_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire4_expand.nbytes)\n",
    "d_result_pool3 = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_pool3.nbytes)\n",
    "\n",
    "d_result_fire5_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire5_squeeze.nbytes)\n",
    "d_result_fire5_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire5_expand.nbytes)\n",
    "d_result_fire6_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_squeeze.nbytes)\n",
    "d_result_fire6_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire6_expand.nbytes)\n",
    "d_result_fire7_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_squeeze.nbytes)\n",
    "d_result_fire7_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire7_expand.nbytes)\n",
    "d_result_fire8_squeeze = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_squeeze.nbytes)\n",
    "d_result_fire8_expand = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_fire8_expand.nbytes)\n",
    "\n",
    "d_result_classifier_conv = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_classifier_conv.nbytes)\n",
    "d_result_classifier = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_result_classifier.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: creat kernels\n",
    "Creat & build program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kernelSource = open(\"squeezenet.cl\").read()\n",
    "program = cl.Program(context, kernelSource).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv3x3 = program.conv2d3x3\n",
    "conv3x3.set_scalar_arg_dtypes([np.int32, np.int32, np.int32, np.int32, np.int32, np.int32, \\\n",
    "                               None, None, None, None])\n",
    "\n",
    "maxpool = program.maxpool2d\n",
    "maxpool.set_scalar_arg_dtypes([np.int32, np.int32, None, None])\n",
    "\n",
    "conv1x1 = program.conv2d1x1\n",
    "conv1x1.set_scalar_arg_dtypes([np.int32, np.int32, \\\n",
    "                               None, None, None, None])\n",
    "\n",
    "avgpool = program.avgpool2d\n",
    "avgpool.set_scalar_arg_dtypes([None, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run OpenCL implement  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rtime = time()\n",
    "#first conv layer\n",
    "conv3x3(queue,(64,), None, 3, 224, 0, 2, 0, 111, d_sample, d_conv1_weight, d_conv1_bias, d_result_conv)\n",
    "maxpool(queue,(64,), None, 111, 55, d_result_conv, d_result_pool1)\n",
    "\n",
    "#block1\n",
    "conv1x1(queue,(16,), None, 64, 55, d_result_pool1, d_fire1_squeeze_weight, d_fire1_squeeze_bias, d_result_fire1_squeeze)\n",
    "conv1x1(queue,(64,), None, 16, 55, d_result_fire1_squeeze, d_fire1_expand1x1_weight, d_fire1_expand1x1_bias, d_result_fire1_expand)\n",
    "conv3x3(queue,(64,), None, 16, 55, 1, 1, 64, 55, d_result_fire1_squeeze, d_fire1_expand3x3_weight, d_fire1_expand3x3_bias, d_result_fire1_expand)\n",
    "\n",
    "conv1x1(queue,(16,), None, 128, 55, d_result_fire1_expand, d_fire2_squeeze_weight, d_fire2_squeeze_bias, d_result_fire2_squeeze)\n",
    "conv1x1(queue,(64,), None, 16, 55, d_result_fire2_squeeze, d_fire2_expand1x1_weight, d_fire2_expand1x1_bias, d_result_fire2_expand)\n",
    "conv3x3(queue,(64,), None, 16, 55, 1, 1, 64, 55, d_result_fire2_squeeze, d_fire2_expand3x3_weight, d_fire2_expand3x3_bias, d_result_fire2_expand)\n",
    "\n",
    "maxpool(queue,(128,), None, 55, 27, d_result_fire2_expand, d_result_pool2)\n",
    "\n",
    "#block2\n",
    "conv1x1(queue,(32,), None, 128, 27, d_result_pool2, d_fire3_squeeze_weight, d_fire3_squeeze_bias, d_result_fire3_squeeze)\n",
    "conv1x1(queue,(128,), None, 32, 27, d_result_fire3_squeeze, d_fire3_expand1x1_weight, d_fire3_expand1x1_bias, d_result_fire3_expand)\n",
    "conv3x3(queue,(128,), None, 32, 27, 1, 1, 128, 27, d_result_fire3_squeeze, d_fire3_expand3x3_weight, d_fire3_expand3x3_bias, d_result_fire3_expand)\n",
    "\n",
    "conv1x1(queue,(32,), None, 256, 27, d_result_fire3_expand, d_fire4_squeeze_weight, d_fire4_squeeze_bias, d_result_fire4_squeeze)\n",
    "conv1x1(queue,(128,), None, 32, 27, d_result_fire4_squeeze, d_fire4_expand1x1_weight, d_fire4_expand1x1_bias, d_result_fire4_expand)\n",
    "conv3x3(queue,(128,), None, 32, 27, 1, 1, 128, 27, d_result_fire4_squeeze, d_fire4_expand3x3_weight, d_fire4_expand3x3_bias, d_result_fire4_expand)\n",
    "\n",
    "maxpool(queue,(256,), None, 27, 13, d_result_fire4_expand, d_result_pool3)\n",
    "\n",
    "#block3\n",
    "conv1x1(queue,(48,), None, 256, 13, d_result_pool3, d_fire5_squeeze_weight, d_fire5_squeeze_bias, d_result_fire5_squeeze)\n",
    "conv1x1(queue,(192,), None, 48, 13, d_result_fire5_squeeze, d_fire5_expand1x1_weight, d_fire5_expand1x1_bias, d_result_fire5_expand)\n",
    "conv3x3(queue,(192,), None, 48, 13, 1, 1, 192, 13, d_result_fire5_squeeze, d_fire5_expand3x3_weight, d_fire5_expand3x3_bias, d_result_fire5_expand)\n",
    "\n",
    "conv1x1(queue,(48,), None, 384, 13, d_result_fire5_expand, d_fire6_squeeze_weight, d_fire6_squeeze_bias, d_result_fire6_squeeze)\n",
    "conv1x1(queue,(192,), None, 48, 13, d_result_fire6_squeeze, d_fire6_expand1x1_weight, d_fire6_expand1x1_bias, d_result_fire6_expand)\n",
    "conv3x3(queue,(192,), None, 48, 13, 1, 1, 192, 13, d_result_fire6_squeeze, d_fire6_expand3x3_weight, d_fire6_expand3x3_bias, d_result_fire6_expand)\n",
    "\n",
    "conv1x1(queue,(64,), None, 384, 13, d_result_fire6_expand, d_fire7_squeeze_weight, d_fire7_squeeze_bias, d_result_fire7_squeeze)\n",
    "conv1x1(queue,(256,), None, 64, 13, d_result_fire7_squeeze, d_fire7_expand1x1_weight, d_fire7_expand1x1_bias, d_result_fire7_expand)\n",
    "conv3x3(queue,(256,), None, 64, 13, 1, 1, 256, 13, d_result_fire7_squeeze, d_fire7_expand3x3_weight, d_fire7_expand3x3_bias, d_result_fire7_expand)\n",
    "\n",
    "conv1x1(queue,(64,), None, 512, 13, d_result_fire7_expand, d_fire8_squeeze_weight, d_fire8_squeeze_bias, d_result_fire8_squeeze)\n",
    "conv1x1(queue,(256,), None, 64, 13, d_result_fire8_squeeze, d_fire8_expand1x1_weight, d_fire8_expand1x1_bias, d_result_fire8_expand)\n",
    "conv3x3(queue,(256,), None, 64, 13, 1, 1, 256, 13, d_result_fire8_squeeze, d_fire8_expand3x3_weight, d_fire8_expand3x3_bias, d_result_fire8_expand)\n",
    "\n",
    "# classifier\n",
    "conv1x1(queue,(1000,), None, 512, 13, d_result_fire8_expand, d_classifier_conv_weight, d_classifier_conv_bias, d_result_classifier_conv)\n",
    "avgpool(queue,(1000,), None, d_result_classifier_conv, d_result_classifier)\n",
    "# Wait for the commands to finish before reading back\n",
    "queue.finish()\n",
    "rtime = time() - rtime\n",
    "print(\"The kernel ran in\", rtime, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#copy result from gpu\n",
    "cl.enqueue_copy(queue, h_result_classifier, d_result_classifier)\n",
    "queue.finish()\n",
    "label_opencl = np.argmax(h_result_classifier)\n",
    "print('the label index prediction of OpenCL implement: %d' % label_opencl)\n",
    "\n",
    "correct_result = im_output_torch.data.numpy().reshape(-1)\n",
    "error = ((correct_result - h_result_classifier) ** 2).sum()\n",
    "print('OpenCL implement error: ', error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
